{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Surprise Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ogJvj59HWbO8pc7KhG5VHUs0dexg2R9V",
      "authorship_tag": "ABX9TyOVJNGNWFYs/cmEDbnQWySy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aishwaryajakka/CourseRecommender/blob/machine_learning/scripts/Surprise_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkzerPXaE-9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "868615f2-5e80-4fbc-9b42-9624aebfd541"
      },
      "source": [
        "# load_data.py\n",
        "!pip install scikit-surprise\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import BaselineOnly\n",
        "from surprise import NormalPredictor\n",
        "from surprise import SVD\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.model_selection import cross_validate\n",
        "from collections import defaultdict\n",
        "# This is to add in the non-taken classes\n",
        "from sklearn.utils.extmath import cartesian\n",
        "\n",
        "# [x] Import taken_course_c table and prepare for model.\n",
        "\n",
        "#TODO replace csv with database connection for taken_course_c table\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Course Recommender/data/cleaned_data/taken_course_c.csv\")\n",
        "grade_key = pd.read_csv(\"/content/drive/My Drive/Course Recommender/data/cleaned_data/grade_c.csv\")\n",
        "course_key = pd.read_csv(\"/content/drive/My Drive/Course Recommender/data/cleaned_data/course_c.csv\")\n",
        "course_ix = course_key.drop_duplicates(subset=\"name\").reset_index(drop=True).reset_index(drop=False).rename(columns={\"index\":\"course_index\"})[[\"name\",\"course_index\"]]\n",
        "course_key = course_key.merge(course_ix, on=\"name\", how=\"left\")\n",
        "print(df.shape)\n",
        "\n",
        "# Remove grades we are not interested in.\n",
        "df = df[df[\"grade_code\"].str.startswith(('A','B','C','D','F')) & ~df[\"grade_code\"].str.startswith('DNG')]\n",
        "# Add Grade as Quality Points\n",
        "df = df.merge(grade_key[[\"grade_code\",\"quality_points\"]], how=\"left\", on=\"grade_code\")\n",
        "# Add course_index to use in place of the unreliable course_id\n",
        "df = df.merge(course_key[[\"course_id\",\"course_index\"]], how=\"left\", on=\"course_id\")\n",
        "# Remove missing course_index for courses not found in the course_c table.\n",
        "## Report Missing Course IDs\n",
        "#df[df.course_index.isnull()][[\"course_id\"]].drop_duplicates().to_csv(\"/content/drive/My Drive/Course Recommender/data/cleaned_data/Missing Course IDs from Courses Table.csv\")\n",
        "df = df.dropna(subset=[\"course_index\"])\n",
        "# Arrange by grade and remove duplicates based on student_id and course_index\n",
        "df = df.sort_values(\"grade_code\").drop_duplicates(subset=(\"student_id\",\"course_index\"))\n",
        "# For safety's sake let's reset the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Table of not taken combinations\n",
        "unique_students = np.unique(df.student_id)\n",
        "unique_course_index = np.unique(df.course_index)\n",
        "df_not_taken = pd.DataFrame(cartesian((unique_students, unique_course_index)), columns=(\"student_id\",\"course_index\"))\n",
        "df_not_taken[\"rating\"] = 0 \n",
        "#outer_join = df.merge(df_not_taken, on=(\"student_id\",\"course_index\"), how = 'outer', indicator = True)\n",
        "#anti_join = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)\n",
        "#keep_right = outer_join[(outer_join._merge == 'right')].drop('_merge', axis = 1)\n",
        "\n",
        "# Check for missing data. \n",
        "# Column; number of missing values\n",
        "print(\"## Check for missing data.\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Option 1: Use Grades as Rating\n",
        "df_grades = pd.DataFrame.copy(df)\n",
        "df_grades[\"rating\"] = df_grades[\"quality_points\"]\n",
        "\n",
        "# Option 2: Use Taken 1/0 as Rating\n",
        "df_taken = pd.DataFrame.copy(df)\n",
        "df_taken[\"rating\"] = 1\n",
        "\n",
        "# Option 1.B: Add not-taking a course as a negative rating 0 (Zero)\n",
        "df_grades_0 = pd.DataFrame.copy(df_grades)\n",
        "not_taken = df_not_taken.merge(df_grades[[\"student_id\",\"course_index\",\"rating\"]], how=\"left\", on=(\"student_id\",\"course_index\"))\n",
        "not_taken = not_taken[not_taken.rating_y.isnull()].rename(columns={\"rating_x\":\"rating\"}).drop(\"rating_y\", axis=1)\n",
        "df_grades_0 = df_grades_0.append(not_taken, ignore_index=True)\n",
        "\n",
        "# Option 2.B: Add not-taking a course as a negative rating 0 (Zero)\n",
        "df_taken_0 = pd.DataFrame.copy(df_taken)\n",
        "not_taken = df_not_taken.merge(df_grades[[\"student_id\",\"course_index\",\"rating\"]], how=\"left\", on=(\"student_id\",\"course_index\"))\n",
        "not_taken = not_taken[not_taken.rating_y.isnull()].rename(columns={\"rating_x\":\"rating\"}).drop(\"rating_y\", axis=1)\n",
        "df_taken_0 = df_taken_0.append(not_taken, ignore_index=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.18.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.12.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n",
            "(65980, 5)\n",
            "## Check for missing data.\n",
            "level_id          0\n",
            "term_id           0\n",
            "course_id         0\n",
            "grade_code        0\n",
            "student_id        0\n",
            "quality_points    0\n",
            "course_index      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyz3yzQloPmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f9a09f0e-2ad4-4f23-ab0b-cd433bef20b2"
      },
      "source": [
        "# Looking at the data\n",
        "print(\"######## Quality Points as Rating Approach #########\")\n",
        "print(df_grades.shape)\n",
        "print(df_grades.rating.dtype)\n",
        "print(df_grades.rating.value_counts())\n",
        "print(df_grades.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######## Quality Points as Rating Approach #########\n",
            "(11111, 8)\n",
            "float64\n",
            "4.00    4920\n",
            "3.75    2099\n",
            "3.00    1673\n",
            "3.25    1518\n",
            "2.75     467\n",
            "2.00     197\n",
            "2.25     143\n",
            "0.25      46\n",
            "1.00      22\n",
            "1.75      17\n",
            "1.25       5\n",
            "0.75       4\n",
            "Name: rating, dtype: int64\n",
            "  level_id  term_id  course_id  ... quality_points  course_index  rating\n",
            "0       GR     2171     113097  ...            4.0         188.0     4.0\n",
            "1       GR     2131     150362  ...            4.0         294.0     4.0\n",
            "2       GR     2144     113149  ...            4.0         225.0     4.0\n",
            "3       GR     2144     113138  ...            4.0         220.0     4.0\n",
            "4       GR     2134     113144  ...            4.0         189.0     4.0\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY_758K-oRco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bc69a80a-ea49-4b93-dbbf-563c15700e0d"
      },
      "source": [
        "print(\"######## Taken=1 as Rating Approach #########\")\n",
        "print(df_taken.shape)\n",
        "print(df_taken.rating.dtype)\n",
        "print(df_taken.rating.value_counts())\n",
        "print(df_taken.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######## Taken=1 as Rating Approach #########\n",
            "(11111, 8)\n",
            "int64\n",
            "1    11111\n",
            "Name: rating, dtype: int64\n",
            "  level_id  term_id  course_id  ... quality_points  course_index  rating\n",
            "0       GR     2171     113097  ...            4.0         188.0       1\n",
            "1       GR     2131     150362  ...            4.0         294.0       1\n",
            "2       GR     2144     113149  ...            4.0         225.0       1\n",
            "3       GR     2144     113138  ...            4.0         220.0       1\n",
            "4       GR     2134     113144  ...            4.0         189.0       1\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI346p7YlakC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "ec1fce16-fcbf-4a09-d1ff-625bbda8aee2"
      },
      "source": [
        "print(\"######## Quality Points as Rating Approach #########\")\n",
        "print(df_grades_0.shape)\n",
        "print(df_grades_0.rating.dtype)\n",
        "print(df_grades_0.rating.value_counts())\n",
        "print(df_grades_0.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######## Quality Points as Rating Approach #########\n",
            "(255360, 8)\n",
            "float64\n",
            "0.00    244249\n",
            "4.00      4920\n",
            "3.75      2099\n",
            "3.00      1673\n",
            "3.25      1518\n",
            "2.75       467\n",
            "2.00       197\n",
            "2.25       143\n",
            "0.25        46\n",
            "1.00        22\n",
            "1.75        17\n",
            "1.25         5\n",
            "0.75         4\n",
            "Name: rating, dtype: int64\n",
            "  level_id  term_id  course_id  ... quality_points  course_index  rating\n",
            "0       GR   2171.0   113097.0  ...            4.0         188.0     4.0\n",
            "1       GR   2131.0   150362.0  ...            4.0         294.0     4.0\n",
            "2       GR   2144.0   113149.0  ...            4.0         225.0     4.0\n",
            "3       GR   2144.0   113138.0  ...            4.0         220.0     4.0\n",
            "4       GR   2134.0   113144.0  ...            4.0         189.0     4.0\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtffcafioI7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2823ac32-4ff7-46c7-daf3-26959d922453"
      },
      "source": [
        "print(\"######## Quality Points as Rating Approach #########\")\n",
        "print(df_taken_0.shape)\n",
        "print(df_taken_0.rating.dtype)\n",
        "print(df_taken_0.rating.value_counts())\n",
        "print(df_taken_0.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######## Quality Points as Rating Approach #########\n",
            "(255360, 8)\n",
            "int64\n",
            "0    244249\n",
            "1     11111\n",
            "Name: rating, dtype: int64\n",
            "  level_id  term_id  course_id  ... quality_points  course_index  rating\n",
            "0       GR   2171.0   113097.0  ...            4.0         188.0       1\n",
            "1       GR   2131.0   150362.0  ...            4.0         294.0       1\n",
            "2       GR   2144.0   113149.0  ...            4.0         225.0       1\n",
            "3       GR   2144.0   113138.0  ...            4.0         220.0       1\n",
            "4       GR   2134.0   113144.0  ...            4.0         189.0       1\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUKsfkMHIBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data set into Surprise\n",
        "## The reader is for the rating_scale. In this case we have a binary scale. \n",
        "#reader = Reader(rating_scale=(0.75, 4.0))\n",
        "reader_taken = Reader(rating_scale=(0,1))\n",
        "data_taken = Dataset.load_from_df(df_taken[['student_id', 'course_index', 'rating']], reader_taken)\n",
        "\n",
        "reader_grades = Reader(rating_scale=(0.0,4.0))\n",
        "data_grades = Dataset.load_from_df(df_grades[['student_id', 'course_index', 'rating']], reader_grades)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyN9D8UgHRm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a572a009-42ff-4e99-a5f0-2c937d87c653"
      },
      "source": [
        "#cross_validate(BaselineOnly(), data_grades, verbose=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.5105  0.5137  0.4949  0.5366  0.5110  0.5133  0.0134  \n",
            "MAE (testset)     0.3968  0.3972  0.3894  0.4018  0.4041  0.3979  0.0051  \n",
            "Fit time          0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n",
            "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (0.013406991958618164,\n",
              "  0.013029098510742188,\n",
              "  0.013040781021118164,\n",
              "  0.012502431869506836,\n",
              "  0.012715816497802734),\n",
              " 'test_mae': array([0.39684699, 0.39718995, 0.38935763, 0.40176157, 0.40414909]),\n",
              " 'test_rmse': array([0.51051509, 0.51365214, 0.49491665, 0.5366471 , 0.51099639]),\n",
              " 'test_time': (0.009784936904907227,\n",
              "  0.008747577667236328,\n",
              "  0.008242368698120117,\n",
              "  0.008115768432617188,\n",
              "  0.008207559585571289)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nS9sX-IoDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6cc9e14c-29aa-4c7b-dd14-e6b24db7b0ef"
      },
      "source": [
        "#cross_validate(NormalPredictor(), data_grades, cv=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (0.007627010345458984, 0.00759577751159668),\n",
              " 'test_mae': array([0.54773416, 0.55162873]),\n",
              " 'test_rmse': array([0.72546806, 0.72454103]),\n",
              " 'test_time': (0.036757469177246094, 0.03740048408508301)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU9YSM2AMY27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determining the strongest approach\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.4, 0.6]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7XRl3EFMZzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "29f39b1f-2d6e-47c3-a321-f92f06abbf33"
      },
      "source": [
        "gs.fit(data_grades)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "# best MAE score\n",
        "print(gs.best_score['mae'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['mae'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5216315747914478\n",
            "0.41182017046108976\n",
            "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
            "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MZ-Zb2mP5u3",
        "colab_type": "text"
      },
      "source": [
        "Best SVD option for using Grades as rating\n",
        "\n",
        "0.4896321029052156\n",
        "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
        "\n",
        "Best SVD option for using Taken=1 as rating.\n",
        "\n",
        "0.014513730229995843\n",
        "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.6}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ay5hB6JMjBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbf3a2f-f552-43ea-f5ee-bf1622c382d5"
      },
      "source": [
        "gs.fit(data_taken)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "# best MAE score\n",
        "print(gs.best_score['mae'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['mae'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.012035013704141048\n",
            "0.0029405187154376952\n",
            "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.6}\n",
            "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBnn4ZLUOljo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get Top-n recommendations\n",
        "def get_top_n(predictions, n=10):\n",
        "    '''Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    '''\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtA7O4WkqcrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}