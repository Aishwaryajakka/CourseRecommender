{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bitbaseconda4629efd241df47b8be61fb0665b6c03d",
   "display_name": "Python 3.6.7 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(65980, 5)\n"
    }
   ],
   "source": [
    "#Import Data\n",
    "\n",
    "#TODO replace csv with database connection for taken_course_c table\n",
    "df = pd.read_csv(\"/Users/andymrkva/git/CourseRecommender/data/cleaned_data/taken_course_c.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "# Remove grades we are not interested in.\n",
    "df = df[df[\"grade_code\"].str.startswith(('A','B','C','D','F')) & ~df[\"grade_code\"].str.startswith('DNG')]\n",
    "# Arrange by grade and remove duplicates\n",
    "df = df.sort_values(\"grade_code\").drop_duplicates(subset=(\"student_id\",\"course_id\"))\n",
    "# Add Taken variable to represent matrix value\n",
    "df[\"taken\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(53544, 6)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      level_id  term_id  course_id grade_code  student_id  taken\n0           GR     2061     115540          A      104387      1\n36008       GR     2094     113142          A      101491      1\n36007       GR     2091     123947          A      101491      1\n36001       GR     2161     113154          A      100896      1\n35997       GR     2144     113085          A      100896      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_id</th>\n      <th>term_id</th>\n      <th>course_id</th>\n      <th>grade_code</th>\n      <th>student_id</th>\n      <th>taken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GR</td>\n      <td>2061</td>\n      <td>115540</td>\n      <td>A</td>\n      <td>104387</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36008</th>\n      <td>GR</td>\n      <td>2094</td>\n      <td>113142</td>\n      <td>A</td>\n      <td>101491</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36007</th>\n      <td>GR</td>\n      <td>2091</td>\n      <td>123947</td>\n      <td>A</td>\n      <td>101491</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36001</th>\n      <td>GR</td>\n      <td>2161</td>\n      <td>113154</td>\n      <td>A</td>\n      <td>100896</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35997</th>\n      <td>GR</td>\n      <td>2144</td>\n      <td>113085</td>\n      <td>A</td>\n      <td>100896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a SparseTensor for efficiency (maybe not needed for this size data set but here we go)\n",
    "\n",
    "def build_taken_sparse_tensor(taken_df):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    taken_df: a pd.DataFrame with `student_id`, `course_id` and `taken` columns.\n",
    "  Returns:\n",
    "    a tf.SparseTensor representing the courses matrix.\n",
    "  \"\"\"\n",
    "  indices = taken_df[['student_id', 'course_id']].values\n",
    "  values = taken_df['taken'].values\n",
    "  return tf.SparseTensor(\n",
    "      indices=indices,\n",
    "      values=values,\n",
    "      dense_shape=[students.shape[0], courses.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "def sparse_mean_square_error(sparse_taken, student_embeddings, course_embeddings):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    sparse_taken: A SparseTensor taken matrix, of dense_shape [N, M]\n",
    "    student_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
    "      dimension, such that U_i is the embedding of student i.\n",
    "    course_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
    "      dimension, such that V_j is the embedding of course j.\n",
    "  Returns:\n",
    "    A scalar Tensor representing the MSE between the true taken and the\n",
    "      model's predictions.\n",
    "  \"\"\"\n",
    "  predictions = tf.gather_nd(\n",
    "      tf.matmul(student_embeddings, course_embeddings, transpose_b=True),\n",
    "      sparse_taken.indices)\n",
    "  loss = tf.losses.mean_squared_error(sparse_taken.values, predictions)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Alternate Solution that is more MEMORY friendly (and probably not needed for this data set)\n",
    "def sparse_mean_square_error(sparse_taken, student_embeddings, course_embeddings):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    sparse_taken: A SparseTensor taken matrix, of dense_shape [N, M]\n",
    "    student_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
    "      dimension, such that U_i is the embedding of student i.\n",
    "    course_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
    "      dimension, such that V_j is the embedding of course j.\n",
    "  Returns:\n",
    "    A scalar Tensor representing the MSE between the true taken and the\n",
    "      model's predictions.\n",
    "  \"\"\"\n",
    "  predictions = tf.reduce_sum(\n",
    "      tf.gather(student_embeddings, sparse_taken.indices[:, 0]) *\n",
    "      tf.gather(course_embeddings, sparse_taken.indices[:, 1]),\n",
    "      axis=1)\n",
    "  loss = tf.losses.mean_squared_error(sparse_taken.values, predictions)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-fa49c072168d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# @title CFModel helper class (run this cell)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCFModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;34m\"\"\"Simple class that represents a collaborative filtering model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-fa49c072168d>\u001b[0m in \u001b[0;36mCFModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   def train(self, num_iterations=100, learning_rate=1.0, plot_results=True,\n\u001b[0;32m---> 27\u001b[0;31m             optimizer=tf.train.GradientDescentOptimizer):\n\u001b[0m\u001b[1;32m     28\u001b[0m     \"\"\"Trains the model.\n\u001b[1;32m     29\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Training a Matrix Factorization model\n",
    "# This is a simple class to train a matrix factorization model using stochastic gradient descent.\n",
    "\n",
    "# @title CFModel helper class (run this cell)\n",
    "class CFModel(object):\n",
    "  \"\"\"Simple class that represents a collaborative filtering model\"\"\"\n",
    "  def __init__(self, embedding_vars, loss, metrics=None):\n",
    "    \"\"\"Initializes a CFModel.\n",
    "    Args:\n",
    "      embedding_vars: A dictionary of tf.Variables.\n",
    "      loss: A float Tensor. The loss to optimize.\n",
    "      metrics: optional list of dictionaries of Tensors. The metrics in each\n",
    "        dictionary will be plotted in a separate figure during training.\n",
    "    \"\"\"\n",
    "    self._embedding_vars = embedding_vars\n",
    "    self._loss = loss\n",
    "    self._metrics = metrics\n",
    "    self._embeddings = {k: None for k in embedding_vars}\n",
    "    self._session = None\n",
    "\n",
    "  @property\n",
    "  def embeddings(self):\n",
    "    \"\"\"The embeddings dictionary.\"\"\"\n",
    "    return self._embeddings\n",
    "\n",
    "  def train(self, num_iterations=100, learning_rate=1.0, plot_results=True,\n",
    "            optimizer=tf.train.GradientDescentOptimizer):\n",
    "    \"\"\"Trains the model.\n",
    "    Args:\n",
    "      iterations: number of iterations to run.\n",
    "      learning_rate: optimizer learning rate.\n",
    "      plot_results: whether to plot the results at the end of training.\n",
    "      optimizer: the optimizer to use. Default to GradientDescentOptimizer.\n",
    "    Returns:\n",
    "      The metrics dictionary evaluated at the last iteration.\n",
    "    \"\"\"\n",
    "    with self._loss.graph.as_default():\n",
    "      opt = optimizer(learning_rate)\n",
    "      train_op = opt.minimize(self._loss)\n",
    "      local_init_op = tf.group(\n",
    "          tf.variables_initializer(opt.variables()),\n",
    "          tf.local_variables_initializer())\n",
    "      if self._session is None:\n",
    "        self._session = tf.Session()\n",
    "        with self._session.as_default():\n",
    "          self._session.run(tf.global_variables_initializer())\n",
    "          self._session.run(tf.tables_initializer())\n",
    "          tf.train.start_queue_runners()\n",
    "\n",
    "    with self._session.as_default():\n",
    "      local_init_op.run()\n",
    "      iterations = []\n",
    "      metrics = self._metrics or ({},)\n",
    "      metrics_vals = [collections.defaultdict(list) for _ in self._metrics]\n",
    "\n",
    "      # Train and append results.\n",
    "      for i in range(num_iterations + 1):\n",
    "        _, results = self._session.run((train_op, metrics))\n",
    "        if (i % 10 == 0) or i == num_iterations:\n",
    "          print(\"\\r iteration %d: \" % i + \", \".join(\n",
    "                [\"%s=%f\" % (k, v) for r in results for k, v in r.items()]),\n",
    "                end='')\n",
    "          iterations.append(i)\n",
    "          for metric_val, result in zip(metrics_vals, results):\n",
    "            for k, v in result.items():\n",
    "              metric_val[k].append(v)\n",
    "\n",
    "      for k, v in self._embedding_vars.items():\n",
    "        self._embeddings[k] = v.eval()\n",
    "\n",
    "      if plot_results:\n",
    "        # Plot the metrics.\n",
    "        num_subplots = len(metrics)+1\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(num_subplots*10, 8)\n",
    "        for i, metric_vals in enumerate(metrics_vals):\n",
    "          ax = fig.add_subplot(1, num_subplots, i+1)\n",
    "          for k, v in metric_vals.items():\n",
    "            ax.plot(iterations, v, label=k)\n",
    "          ax.set_xlim([1, num_iterations])\n",
    "          ax.legend()\n",
    "      return results\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}